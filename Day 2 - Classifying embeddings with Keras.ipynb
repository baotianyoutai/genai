{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97a6d93-5744-4215-b4b7-255b4b22488a",
   "metadata": {},
   "source": [
    "# Day 2 - Classifying embeddings with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c6a28b-72ac-4928-afc9-28b9891a725a",
   "metadata": {},
   "source": [
    "このノートブックでは、Gemini APIによって生成された埋め込みを使用して、ニュースグループの投稿を投稿内容からカテゴリ（ニュースグループ自体）に分類できるモデルをトレーニングする方法を学びます。\n",
    "\n",
    "この手法は、Gemini APIの埋め込みを入力として使用し、テキスト入力を直接トレーニングする必要がなくなり、その結果、テキストモデルをゼロからトレーニングするよりも、比較的少ない例を使用してかなりうまく実行できます。\n",
    "\n",
    "* テキストからメールアドレスを削除できるようになる\n",
    "* genaiを使って、分類タスク用の埋め込みを作成できるようになる\n",
    "* kerasモデルを構築できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e642a5d-456b-4aa2-bfea-1be8bb4b9ac8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up  the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aff2f30-648a-48a7-adc3-04fcd6318e94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -qU google-genai\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b73c74-a13d-48d1-927a-054f72bc7a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "\n",
    "client = genai.Client(vertexai = True, location = \"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5ee17-1f03-4584-b24a-0f771547b860",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "[20のニュースグループテキストデータセット](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)には、トレーニングセットとテストセットに分けられた20のトピックに関する18,000のニュースグループ投稿が含まれています。トレーニングデータセットとテストデータセットの分割は、特定の日付の前後に投稿されたメッセージに基づいています。このチュートリアルでは、トレーニングセットとテストセットのサンプルサブセットを使用し、Pandasを使用していくつかの処理を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5038b6-0f6a-4299-a360-5f8a8f3d71b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset = \"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6da7cf-3175-4167-a2a2-2439614d9994",
   "metadata": {},
   "source": [
    "---\n",
    "以下は、トレーニングセットのレコードがどのように見えるかの例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833a3ebf-8e88-4490-9e07-ac544c283ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e578df-fcb7-400f-872a-4927e8fce8f4",
   "metadata": {},
   "source": [
    "Pandasデータフレームでこのチュートリアルのデータを前処理することから始めます。名前やメールアドレスなどの機密情報を削除するには、各メッセージの件名と本文のみを削除します。これはオプションのステップで、入力データを電子メールの投稿ではなく、より一般的なテキストに変換して、他のコンテキストでも機能します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effc0e3e-9ae9-4705-999e-251ff52165f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # Extract only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncate each entry to 5,000 characters\n",
    "    return text\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Put data points into dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\" : newsgroup_dataset.data, \"Label\" : newsgroup_dataset.target}\n",
    "    )\n",
    "    # Clean up the text\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Match label to target name index\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l : newsgroup_dataset.target_names[l])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6228c8-5cf9-42b8-a05e-c97aa6578b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9435d76-3aea-4078-a3d5-fc8ced61b8a7",
   "metadata": {},
   "source": [
    "次に、トレーニングデータセットで100のデータポイントを取り、いくつかのカテゴリをドロップしてこのチュートリアルを実行して、データの一部をサンプリングします。比較する科学のカテゴリーを選択してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fc4c0dd-92b9-4963-9f79-46d014e1ff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Sample rows, selecting num_samples of each Label.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "    \n",
    "    # We have fewer categories now, so re-calibrate the label encoding.\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de805c58-3b9a-4842-9a83-361380cd5ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "# Class name should contain 'sci' to keep science categories.\n",
    "# Try different labels from the data - see newsgroups_train.target_names\n",
    "CLASSES_TO_KEEP = \"sci\"\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c8ebe6-260a-439b-b21c-b57faf05b60d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          100\n",
       "sci.electronics    100\n",
       "sci.med            100\n",
       "sci.space          100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d97c3df-2cab-4545-940b-84bbca4f0da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          25\n",
       "sci.electronics    25\n",
       "sci.med            25\n",
       "sci.space          25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24142d0d-40e1-4da6-be25-5137a15df424",
   "metadata": {},
   "source": [
    "# 埋め込みEmbeddingの作成\n",
    "このセクションでは、Gemini API埋め込みエンドポイントを使用して、各テキストの埋め込みを生成します。埋め込みの詳細については、[埋め込みガイド](https://ai.google.dev/docs/embeddings_guide)を参照してください。\n",
    "\n",
    "注：埋め込みは一度に1つずつ計算されるため、サンプルサイズが大きいと時間がかかる可能性があります。\n",
    "\n",
    "## Task type\n",
    "Text-embedding-004モデルは、特定のタスクに合わせた埋め込みを生成するタスクタイプパラメータをサポートしています。\n",
    "Task Type | Description\n",
    "---       | ---\n",
    "RETRIEVAL_QUERY\t| Specifies the given text is a query in a search/retrieval setting.\n",
    "RETRIEVAL_DOCUMENT | Specifies the given text is a document in a search/retrieval setting.\n",
    "SEMANTIC_SIMILARITY\t| Specifies the given text will be used for Semantic Textual Similarity (STS).\n",
    "CLASSIFICATION\t| Specifies that the embeddings will be used for classification.\n",
    "CLUSTERING\t| Specifies that the embeddings will be used for clustering.\n",
    "FACT_VERIFICATION | Specifies that the given text will be used for fact verification.\n",
    "\n",
    "今回はCLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb0edd7c-52e1-4f83-ae0f-5e757e90f657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "import tqdm\n",
    "from tqdm.rich import tqdm as tqdmr\n",
    "import warnings\n",
    "\n",
    "# Add tqdm to Pandas...\n",
    "tqdmr.pandas()\n",
    "\n",
    "# ...But suppress the experimental warning.\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e : (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "@retry.Retry(predicate = is_retriable, timeout = 300.0)\n",
    "def embed_fn(text : str) -> list[float]:\n",
    "    # You will be performing classification, so set task_type accordingly.\n",
    "    response = client.models.embed_content(\n",
    "        model = \"text-embedding-004\",\n",
    "        contents = text,\n",
    "        config = types.EmbedContentConfig(\n",
    "            task_type = \"CLASSIFICATION\"\n",
    "        )\n",
    "    )\n",
    "    return response.embeddings[0].values\n",
    "\n",
    "def create_embeddings(df):\n",
    "    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3839494e-20b8-4c60-a9c6-db557a5f2b28",
   "metadata": {
    "tags": []
   },
   "source": [
    "このコードは明確化のために最適化されており、特に高速ではありません。これは、読者が[バッチ](https://ai.google.dev/api/embeddings#method:-models.batchembedcontents)または並列/非同期埋め込み生成を実装するための演習として残されています。このステップを実行するには時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8ba640-e1f5-47f1-bef6-2ad9dce43447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb994be2acf49b0986eeed257fd7ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4361798ff7f4e049e7b8989466c3898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = create_embeddings(df_train)\n",
    "df_test = create_embeddings(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535139bd-251e-4fdb-8302-db93ab40bf95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Encoded Label</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Privacy &amp; Anonymity on the Internet FAQ (2 of ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.005880952347069979, 0.013432726263999939, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Re: text of White House announcement and Q&amp;As ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0086032934486866, 0.03312867134809494, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>Re: Once tapped, your code is no good any more...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0007966440753079951, 0.02588818222284317, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Clipper considered harmful\\n\\nIf Clipper comes...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.026746241375803947, 0.026608575135469437, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>Re: What the clipper nay-sayers sound like to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.003544179257005453, 0.023313341662287712, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label Class Name  \\\n",
       "1100  Privacy & Anonymity on the Internet FAQ (2 of ...     11  sci.crypt   \n",
       "1101  Re: text of White House announcement and Q&As ...     11  sci.crypt   \n",
       "1102  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n",
       "1103  Clipper considered harmful\\n\\nIf Clipper comes...     11  sci.crypt   \n",
       "1104  Re: What the clipper nay-sayers sound like to ...     11  sci.crypt   \n",
       "\n",
       "      Encoded Label                                         Embeddings  \n",
       "1100              0  [-0.005880952347069979, 0.013432726263999939, ...  \n",
       "1101              0  [-0.0086032934486866, 0.03312867134809494, -0....  \n",
       "1102              0  [0.0007966440753079951, 0.02588818222284317, -...  \n",
       "1103              0  [0.026746241375803947, 0.026608575135469437, -...  \n",
       "1104              0  [0.003544179257005453, 0.023313341662287712, -...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1fc8c9-216c-4105-bda4-c2d2cea5ff6a",
   "metadata": {},
   "source": [
    "# 分類モデルを構築する\n",
    "ここでは、生の埋め込みデータを入力として受け入れ、1つの隠しレイヤーと、クラスの確率を指定する出力レイヤーを持つシンプルなモデルを定義します。予測は、テキストが特定のクラスのニュースである確率に対応します。\n",
    "\n",
    "モデルを実行すると、Kerasはデータポイントのシャッフル、メトリクスの計算、その他のMLボイラープレートなどの詳細を処理します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6317c300-7559-4467-b445-9ba8dedd4bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 12:26:04.886285: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-16 12:26:04.894290: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-16 12:26:04.910216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747398364.935429   15781 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747398364.941591   15781 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747398364.958833   15781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747398364.958879   15781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747398364.958882   15781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747398364.958885   15781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-16 12:26:04.966798: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q keras tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def build_classification_model(input_size : int, num_classes : int) -> keras.Model:\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input([input_size], name = \"embedding_inputs\"),\n",
    "            layers.Dense(input_size, activation = \"relu\", name = \"hidden\"),\n",
    "            layers.Dense(num_classes, activation = \"softmax\", name = \"output_probs\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52687e72-2b3d-4c46-a4b8-b9691424c73a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_probs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,076</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │       \u001b[38;5;34m590,592\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_probs (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m3,076\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Derive the embedding size from observing the data. The embedding size can also be specified\n",
    "# with the `output_dimensionality` parameter to `embed_content` if you need to reduce it.\n",
    "\n",
    "embedding_size = len(df_train[\"Embeddings\"].iloc[0])# 768\n",
    "\n",
    "classifier = build_classification_model(\n",
    "    embedding_size, len(df_train[\"Class Name\"].unique())\n",
    ")\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdfb266-a9fe-4b4b-92e5-1aa9b5db55b0",
   "metadata": {},
   "source": [
    "---\n",
    "# モデルの学習\n",
    "最後に、モデルを訓練することができます。このコードは、損失値が安定するとトレーニングループを終了するために早期停止を使用するため、実行されるエポックループの数は指定された値と異なる場合があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "837227b4-4e06-4abc-be5b-bb79e7974357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Encoded Label</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Privacy &amp; Anonymity on the Internet FAQ (2 of ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.005880952347069979, 0.013432726263999939, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Re: text of White House announcement and Q&amp;As ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0086032934486866, 0.03312867134809494, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>Re: Once tapped, your code is no good any more...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0007966440753079951, 0.02588818222284317, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Clipper considered harmful\\n\\nIf Clipper comes...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.026746241375803947, 0.026608575135469437, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>Re: What the clipper nay-sayers sound like to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.003544179257005453, 0.023313341662287712, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label Class Name  \\\n",
       "1100  Privacy & Anonymity on the Internet FAQ (2 of ...     11  sci.crypt   \n",
       "1101  Re: text of White House announcement and Q&As ...     11  sci.crypt   \n",
       "1102  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n",
       "1103  Clipper considered harmful\\n\\nIf Clipper comes...     11  sci.crypt   \n",
       "1104  Re: What the clipper nay-sayers sound like to ...     11  sci.crypt   \n",
       "\n",
       "      Encoded Label                                         Embeddings  \n",
       "1100              0  [-0.005880952347069979, 0.013432726263999939, ...  \n",
       "1101              0  [-0.0086032934486866, 0.03312867134809494, -0....  \n",
       "1102              0  [0.0007966440753079951, 0.02588818222284317, -...  \n",
       "1103              0  [0.026746241375803947, 0.026608575135469437, -...  \n",
       "1104              0  [0.003544179257005453, 0.023313341662287712, -...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "976f8092-27fa-45d3-9bd2-d180c8b1e5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.3956 - loss: 1.3638 - val_accuracy: 0.8000 - val_loss: 1.2354\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8432 - loss: 1.1709 - val_accuracy: 0.8200 - val_loss: 1.0639\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8865 - loss: 0.9824 - val_accuracy: 0.8700 - val_loss: 0.8873\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9337 - loss: 0.7474 - val_accuracy: 0.8400 - val_loss: 0.7235\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9421 - loss: 0.5799 - val_accuracy: 0.9000 - val_loss: 0.5976\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9582 - loss: 0.4540 - val_accuracy: 0.9400 - val_loss: 0.4908\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9808 - loss: 0.3291 - val_accuracy: 0.8900 - val_loss: 0.4521\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.2577 - val_accuracy: 0.9100 - val_loss: 0.3910\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9785 - loss: 0.2178 - val_accuracy: 0.9100 - val_loss: 0.3558\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9848 - loss: 0.1607 - val_accuracy: 0.9300 - val_loss: 0.3362\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.1532 - val_accuracy: 0.9200 - val_loss: 0.3197\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.1212 - val_accuracy: 0.9200 - val_loss: 0.3033\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9856 - loss: 0.1239 - val_accuracy: 0.9300 - val_loss: 0.2906\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9922 - loss: 0.0860 - val_accuracy: 0.9300 - val_loss: 0.2899\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9931 - loss: 0.0920 - val_accuracy: 0.9400 - val_loss: 0.2728\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9974 - loss: 0.0768 - val_accuracy: 0.9200 - val_loss: 0.2827\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0726 - val_accuracy: 0.9300 - val_loss: 0.2651\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9400 - val_loss: 0.2623\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9974 - loss: 0.0554 - val_accuracy: 0.9300 - val_loss: 0.2669\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0429 - val_accuracy: 0.9300 - val_loss: 0.2568\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "x_train = np.stack(df_train[\"Embeddings\"])# (400, 768)\n",
    "y_train = df_train[\"Encoded Label\"]\n",
    "\n",
    "x_val = np.stack(df_test[\"Embeddings\"])# (100, 768)\n",
    "y_val = df_test[\"Encoded Label\"]\n",
    "\n",
    "# Specify that it's OK to stop early if accuracy stabilises.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"accuracy\", patience = 3)\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "history = classifier.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    validation_data = (x_val, y_val),\n",
    "    callbacks = [early_stop],\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c6ba3-9f64-4cf0-b9b7-b81d50056ccd",
   "metadata": {},
   "source": [
    "# モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44b58414-2707-4984-862d-5ecfa8ccc207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9262 - loss: 0.2794 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9300000071525574, 'loss': 0.2567942142486572}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x = x_val, y = y_val, return_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998928f1-3a74-4bd4-a00b-25eb197f6af3",
   "metadata": {},
   "source": [
    "モデルトレーニング指標の視覚化方法など、Kerasを使用したトレーニングモデルの詳細については、[組み込みのメソッドを使用したトレーニングと評価]((https://www.tensorflow.org/guide/keras/training_with_built_in_methods))を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f5477-2959-4566-bf55-b0297ec9fcc5",
   "metadata": {},
   "source": [
    "# モデルの予測\n",
    "\n",
    "優れた評価指標を備えたトレーニングされたモデルが手に入ったので、新しい手書きデータで予測を試みることができます。提供された例を使用するか、独自のデータを試して、モデルがどのように機能するかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b4cb26d-4b38-4482-8a0b-c7e3f2cebe1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_prediction(text : str) -> list[float]:\n",
    "    \"\"\"Infer categories from the provided text.\"\"\"\n",
    "    #Remember that the model takes embeddings as input, so calculate them first.\n",
    "    embedded = embed_fn(new_text)\n",
    "    # And recall that the input must be batched, so here they are wrapped as a\n",
    "    # list to provide a batch of 1.\n",
    "    inp = np.array([embedded])\n",
    "    \n",
    "    # And un-batched here.\n",
    "    [result] = classifier.predict(inp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9632aef-a4ae-4192-bb28-817f945736fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "sci.crypt: 0.02%\n",
      "sci.electronics: 0.30%\n",
      "sci.med: 0.04%\n",
      "sci.space: 99.64%\n"
     ]
    }
   ],
   "source": [
    "# This example avoids any space-specific terminology to see if the model avoids\n",
    "# biases towards specific jargon.\n",
    "new_text = \"\"\"\n",
    "First-timer looking to get out of here.\n",
    "\n",
    "Hi, I'm writing about my interest in travelling to the outer limits!\n",
    "\n",
    "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
    "\n",
    "Let me know how to do that please.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result = make_prediction(new_text)\n",
    "\n",
    "for idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n",
    "    print(f\"{category}: {result[idx] * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5dd86-6fdf-48b7-82ca-46fd9390c0d3",
   "metadata": {},
   "source": [
    "Kerasでカスタムモデルをトレーニングする詳細については、[Kerasガイド](https://keras.io/guides/)をご覧ください。"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
